## Research Seminars in Statistics at Stockholm University - Spring 2023

---
### **Spring 2023**

[Sebastian Ankargren](https://scholar.google.com/citations?hl=sv&user=G3XbN5MAAAAJ), Spotify, Stockholm\
Abstract: We introduce SMARTboost (boosting of symmetric smooth additive regression trees), a machine learning model capable of fitting complex functions in high dimensions, yet designed for good performance in small n and low signal-to-noise environments. SMARTboost inherits many of the qualities that have made boosted trees the most widely used machine learning tool for tabular data; it automatically adjusts model complexity, handles continuous and discrete features, can capture nonlinear functions in high dimensions without overfitting, performs variable selection, and can handle highly non-Gaussian features. The combination of smooth symmetric trees and carefully designed Bayesian priors gives SMARTboost an edge (in comparison with a state-of-the-art tool like XGBoost) in many settings with continuous and mixed discrete-continuous features. Unlike other tree-based methods, it can also compute marginal effects.

When? **Jan 25, 2022, at 1 pm**\
Where? Campus Albano, **TBA**, house 2, level 2.

---

[Johan Koskinen](https://scholar.google.com/citations?user=IRwn3fYAAAAJ&hl=sv&oi=ao), Dept of Statistics, Stockholm University\
Abstract: We introduce SMARTboost (boosting of symmetric smooth additive regression trees), a machine learning model capable of fitting complex functions in high dimensions, yet designed for good performance in small n and low signal-to-noise environments. SMARTboost inherits many of the qualities that have made boosted trees the most widely used machine learning tool for tabular data; it automatically adjusts model complexity, handles continuous and discrete features, can capture nonlinear functions in high dimensions without overfitting, performs variable selection, and can handle highly non-Gaussian features. The combination of smooth symmetric trees and carefully designed Bayesian priors gives SMARTboost an edge (in comparison with a state-of-the-art tool like XGBoost) in many settings with continuous and mixed discrete-continuous features. Unlike other tree-based methods, it can also compute marginal effects.

---